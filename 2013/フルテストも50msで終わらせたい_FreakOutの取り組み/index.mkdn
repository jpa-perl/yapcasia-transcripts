# フルテストも50msで終わらせたい 〜 FreakOutの取り組み 〜 

2日間お疲れ様でした。前夜祭からいうと3日ですか。ずっと人の話を聞くというのは結構疲れると思うので、簡単に進めたいなと思います。

僕のトークは、「フルテストも50msで終わらせたい」というタイトルで、Perlのmake testが遅くなってきたのでそれをどう解決したか、そういう話をしたいと思います。

自己紹介ですが、僕は久森達郎（ヒサモリ・タツロウ）といいます。だいたいmyfinderっていうIDでtwitterなどをしています。FreakOutという会社に勤めてまして、今はインフラのチームにいてサーバーの面倒を見たり、あとはグラフとにらめっこしたり、そういった仕事がメインです。



去年は嬉しいことにフリークアウトのシステムをご紹介して、Best Talk Awards 3を頂きまして、非常にありがたく思っております。

50ms or die

こういう感じですね。

で、最初にお断りしておきますが、さすがに50msではメインテストは終わりません。それは無理です。

今日話すことは、Perlアプリケーションの基本的なところ。それからFreakOutのテスト環境とCIというのはどうやってきたかとか、どういう推移でここ1、2年やってきたかみたいなお話をして、それから増えたテストをどうやって高速化していくかみたいな話になります。

今回話さないこと

今日は、画面系のテストに関しては話しません。昨日の午前中に同僚のモリヤマさんがBrowserStackを使ったテストについて話をしてくれました。この資料は確かもう上がっているはずなので、そちらを探してください。

Real Time Biddingそのもの、FreakOutのシステム自体の話では、昨年のトークの資料で、WEB+DB PRESSに書いた記事があるので、そちらを参照してください。ボリューム70なので今本屋には置いてないですけど、総集編があります。

Web-DB press総集編Vol.1〜72の表紙

こういう表紙です。皆さん、ぜひお買い求めください。

あと、テストモジュールに関して踏み込んだ使い方みたいなところは、昨日のsoh335さんの話とかなり重複していたので、スキップしようかなと思います。ですので、最初に話したPerlのテストおさらいをさらっと流す感じで話していきます。

Perlのテストのおさらい

最初にPerlのテストなんですけど、わりとちゃんと自分のプロダクトではPerlのテストを書いているという方はどのくらいいらっしゃいますか？（客に手を挙げさせる）素晴らしい。みんな書いてる。でも、書いているといっても10％ですね。

ということで、いろいろと基本的なモジュールに関して話していこうと思ってたんですけど、この辺は（スライドを流していく）、Test::More、Test::MockTime、Plack::Test、Test::mysqld、だいたいこれくらい使えば基本的なテスト用途は満たせます。ここは全部重複していたので、soh335さんのスライドの資料にお任せします。

FreakOutのテスト環境とCIの話なんですけど、基本的にアプリケーションはPlack::Testでだいたい片がつくケースが多くて、画面系以外のところに関してはほとんどHTTPの通信とかで、画面とか伴わないので、基本的にリクエスト/レスポンスに落としやすいんですね。

ちょっと潰れちゃってますが、Plack::TestのSYNOPSISに書いてあるようなものをそのまま書いただけです。これでリクエストとアプリケーションを作って、そのテストの中でそれを使ってリクエストを実行してテストする、そんな感じです。

CLI（バッチ）処理

では、CLIとかについてはどうしているかというと、単独のモジュールで開発した後、CLIラッパーみたいなモジュール、フレームワークが社内にあるので、それを使ってラップして呼び出しているので、基本的にはCLIを意識してモジュールを書くというよりは、処理を書いてそれをCLIでラップしてというような作り方をしています。

ログ処理

ログ処理については、基本的にはダミーのログを特定のディレクトリに置いて、そこでそれを対象に集計処理とかをかけて、処理後はクリーンアップするという形です。まあ一般的にみなさんがよくやるような処理をやっています。

これはsoh335さんも話してたんですけど、うちもt::Utilsというのに入っていて、ここでテストを捗らせるために、接続先DBをテスト用に置き換えたり、テストごとにミドルウェア起動して空いているポートを探したりというのは、全部こういうt::Utilsの下にこういうモジュールを作って、それをuseすることで処理して、毎回テストでは書かないようにしています。

ですので、Perl以外のミドルウェア、mysql、memcached、あとTT(Tokyo Tyrant)を使っていますけど、それ以外にRiakとかも入れ始めたので、Riakの起動停止もこのへんでフォローしています。

リスト

こんな感じですね。config fileを最初に上書きして、そのあとの下は別途メソッドにしているんですけど、test memdとか、test●とか、test dbとか、そういう感じですね。これでinitializeしている、そんな流れです。

ヘルパモジュール

もう1個、ヘルパモジュールというのを書いているんですが、これは、別途手元でmake testを走らせたいときとかに、Test::Prettyに差し替えたいような要求を吸収するために作っています。そして、runtests、あとは、runtestsのテスト一覧を渡す前にシャッフルするみたいなことをやっています。

Makefile.PL

Makefile.PLと書かれています。潰れちゃってますが、見えますか？ スライドは上げるので見て下さい。Makefileの中にMT::test_via_harnessという、自分のモジュールに置き換えてそれを処理してもらうという書き方をしていて、その実際のMakeHelperの中で、こんな感じでHarness classに置き換えて、引数にprettyが当たっていればTest::Prettyを使うことができます。

テストをシャッフルするっていうのもやっています。これは単純にFile::Findで持ってきて、最後シャッフルをかけてruntestsに渡すということです。

これはもしやってない人がいたらやったほうがいいなと思っている策です。知らない間に、順序に依存するテストを書いてしまうことってあると思うんですよ。あと、自分が書いたテストの結果に依存したテストをほかの人が書いちゃうことがあって。最後のはいいです。

具体的にはDBのクリーンアップ漏れが発生して、本当は消えてなければいけないレコードが入っていることを期待するテストを書いちゃうとか、ほかの人がクリーンアップするように直したほかのテストをfailしちゃうみたいなケースとかは、なかなか気づけないんですよね。

あと、同じファイルを違うテストから参照するケースとかも、本当はFile::Tempとかを使ってそのテストで閉じたものをやるべきなんですけど、そうなってない場合には、コンフリクトする可能性があります。これはわりとサクッとできるので、もしまだやってない方がいたらやったほうがいいかなと思います。

Ukigumoとのつきあい

次は、Ukigumoとのつきあいについてです。Ukigumoサーバーには、特に手は入れてません。そのまま立ち上げているだけです。Ukigumoクライアントは使ってなくて、独自にクライアントを実装してます。

社内ではFOutTesterという名前で作っていて、CIを開始するための枠組みで、テストに未実効のブランチがあるかないかをバッチで毎分kickして探してきて実行します。SQLiteに実行したブランチ名とリビジョンを記録しておいて、2回同じテストを走らせないようにしている、という感じです。そしてテスト結果をUkigumoサーバー以外にポストするという処理をそこに書いています。今はせいぜいメールぐらいですけれども、IRCを使っている場合はそこでIRCにpostしてもいいのかなと思います。

画面を変えている

こんな感じでテスターのbase classを作っていて、その中で、実体はこのrunの中か、このgithubのリポジトリを取ってきて、指定のプロジェクトをrunして、結果までparseされてUkigumoに投げます。Ukigumoに投げる処理は、普通にLWPに任せるみたいな話の処理だというのがわかります。

これを継承したそれぞれのプロジェクトもあります。ファイルが…これだと読めませんかね。

ここまでのまとめ

ここまでは、基本的なFreakOutのテストとUkigumoとの付き合いについて説明しました。

実施済みのブランチを記録して2回実行させないとか、テストを実行するにあたってヘルパモジュールをつくって捗らせています。

では、いったんここまでで小休止したいんですが、ご質問等があれば手を挙げていただけますか？その隙に水を飲ませてください。特にございませんか？ 大丈夫そうですね。

じゃあ次に行きます。ここからようやく、本題の「増えたテストの実行の高速化」っていう話になります。その前に、FreakOutのテストはここまで形を作りましたけど、ここに行くまで結構いろいろありまして、1〜2年間はこんな感じで遷移しました。

去年のYAPC前までは3〜4人で開発してまして、あんまりちゃんとCIとかは整備してなかったんです。手元のVMで実行して、よければチェックしてマージしてリリースということをやってたんですね。

でも、すぐに結構な人数になってきたので、ここでCIを入れようということになったんです。メンバーみんなでCI環境を急速に整備していって、ここまでで話したようなものを作りました。

今年に入ってからさらに倍ぐらいの人数に増えて、ブランチなどの数が増えてきてプッシュされるとテストが走るようになっているので、同時に実行したいテストのCI実行順番待ちが出るようになってしまいました。単体でも時間がかかるので、順番待ちをしているとさらに時間がかかるというような状況です。

現状としては、.t file（ドット･ティー･ファイル）だけでも800以上、直近で渋谷(会場にいる同僚)さん、何件ありましたっけ？僕が見たメールで830いくつとか、そのぐらいです。そのくらいのテストファイルがあって、これ、make testを愚直に打つと2,000秒ぐらい、30〜40分返って来なくて、結構つらいねという感じでした。

そもそも時間がかかりすぎなんです。ブランチがいくつもあると、結果がわかるまでにすごく待たされてしまう。例えば5個開発ブランチがあって、活発にプッシュされていると3時間ぐらい待たされる。プッシュしたらもうその日は結果がわかるまでリリースできないけど、結果がわかるのが8時を過ぎてしまうからDeployできなくてまた翌日になるというような、開発速度がすごく遅くなるという事態が起こるという状況になってきてしまいました。

こんな感じで待たされた末にfailしていると、切なくてちょっとやる気がなくなっちゃいますよね。そうなると、事故るリスクが高まってくるのはどうしてかというと、テストは遅いし、CIを通すと遅いから、もう手元でとりあえずテストを通して、オッケーならマージして出しちゃえみたいなことをやる人が出てきたりするからなんです。そして誰もフルテストをしなくなっていくと、せっかくここまでサイクルを作ったのに全然使われなくて形骸化していってしまう。そうなると意味がないですよね。

これは同僚のツィートなんですけど、関係ないと思っててもテストが落ちたというケースが出てきます。フルテストを通さないと気づかないっていうことも多々あるので、やっぱり常にフルテストを早く通し続けるっていう環境を作らないといけないよね、というような話です。テストするのをやめるのは論外なんですが、かといってテストが終わるまで愚直に待つのは全然解決になってない。

proveには-j（ハイフンジェイ）ってオプションがあるんですけど、ちょっと深遠な理由でこれを使えないと。使うとfailすることがあるので、これを使うには大幅に改修しなければいけないという事案が1件あったのと、それ以外の高速化で事前起動できるものは競合を起こさないものの対応を進めたりはしています。たださっきもお話した通り、テストの数が多いので、やっぱり単独での高速化はどこかで限界を迎えるでしょうという話になりました。

だから、スケールするやり方に変わらなければいけないということで、高速化にあたっては、こんな感じで要件を決めました。

まず、すでに書いてあるテストはそのままで触らなくていい。既存のCIサーバーもそのまま使いたい。Ukigumoは、Ukigumo::Serverについては引き続き使いたい。ですので、これはちょっとそのままにしようという話をしました。

それから、先ほど話したんですけど、やっぱりちゃんとスケールすること。例えばテスト数が10倍になっても、並行する開発数が10倍になったというような状況になっても吸収できる枠組みであること、というのが要件でした。

そこで、分散実行させましょうというアイデアを立てました。複数のサーバーに分散してリクエストを投げて、その実行結果を返して集計するということができれば、ノードを追加してスケールするという枠組みに落とせそうだなという感触があったからです。

また、サーバーの追加やメンテが簡単にできるように、簡単なコンフィグファイルだけでサーバーノードを管理すればいいよね、というのが理想でした。

それと、複数のサーバーにリクエストを投げると、ネットワークとか何らかの理由で1台のサーバーがフェイルしたみたいなことがあるので、まず再実行というものをできるようにしようとしました。これについては、SQLiteを実行済みのブランチなんかは保存するようにして、そのあたりは簡単にコントロールできるように実装しました。

分散実行の仕組み

で、簡単にいうとこういうことになります。サーバーノードの中でブランチ、そのプッシュされたブランチの中に入っている実行対象テストのリストを取ってきて、クラスターの台数分で等分割します。その等分割したテストの一覧を各サーバーに投げて実行した結果を返してもらって集計して、Ukigumoとそれ以外というようなレポート名になってますけど、そういったファイルをポストするという仕組みです。

このへんは、それぞれよく知られたCPANモジュールだけで書けるので、実際にやってることはすごく簡単です。例えばテストのピックアップとシャッフルというのはFile::FindとList::MoreUtilsで普通に分割して、クラスター名をキーにした配列とかに入れ込んでおけば割り当てができますね。クラスターノードでの実行命令とか結果受取はシリアルにやってしまうとまずいんですが、Parallel::ForkManagerを使えばできます。結果のパースとかはPerlの得意なところなので言わずもがなですね。Ukigumoへのポストは、先ほどのコードの通り、LWPで書いてポストすることで終わらせるという感じです。

これがサーバー側なんですけど、実行するクラスター側は何をやっているかというともっと簡単で、TAP::Harness::runtestsにテスト一覧を渡して実行するだけです。

コードサンプルで解説

ではここで、コードサンプルで解説します。

あー、これは見えないな。見えないですけど、単にハッシュに突っ込んでるPerlのファイルです。これは飛ばします。

これは実行することは単純で、Parallel::ForkManagerでコンフィグに書かれている台数分だけプロセスを上げて、それぞれforで回して、Net::OpenSSHでテストリストを投げて、先にgit fetchさせて、最終的に実行した結果を受け取っています。

最近のParallel::ForkManagerだと、run_on_finishはどこかというmethodで、フィニッシュしたときに任意のcode refみたいなものを渡して、処理に渡してデータを集計できるので、子プロセスでsshを投げて、クラスターノードの実行した結果を受け取ったら、親プロセスに渡すときにこういうやり方をすると簡単に取れます。バージョンがいくつだったかは忘れましたけど、新しいParallel::ForkManagerを入れると、とても捗ります。

パースするところは、全部のテストがどのくらい走ったかと、どのくらいフェイルしたかしか計測してなくて、単純に集計するだけになっています。

これがクラスターノードで実行しているランチャーなんですけど、本当に簡単なんです。今はわからないんですけど、オプションとしてデリミタでリストを渡してますけど、それをスクリプトしてruntestsに渡すだけですから。こっち側ではシャッフルする必要はありません。もうマスターの側でシャッフルはしてあるので、ここは受け取って実行するだけでいいんです。

再実行

これは実行するところなんですけど、次は再実行の話です。再実行するときはマスターノードで再実行用のWeb appを起動しておいて、リクエストをかけたらその実施状況を保存しているSQLiteからそのブランチを削除するだけのような、簡単なアプリケーションを起動して待つだけです。

あと、これはkanさんが書いてくれたんですけど、Chrome拡張でUkigumoのサーバーにボタンを追加するという対応で、再実行が簡単にできるようにしています。画面はこんな感じで、この「リトライ」っていうボタンを追加するような、そんな対応をしています。このフェイルしてるっていう内容が、単純にテストだけでコケている場合だったら直すべきなんですけど、特定のサーバーだけ応答がないとかっていう結果が出てる場合は、再実行ができるようになっています。

動かすサーバー

動かしているサーバーは、社内にこんな感じで余っていた自作サーバーのパーツを寄せ集めて作ってます。ですので、ご家庭にあり合わせのパーツが余っていれば、それでも作れます。これはうちの事情なんですけど、まあAWSでいいんじゃないかと思います。必要な時間だけサーバーの動作をスタートして、いらなくなったり就業時間が終わったりしたらストップする、そんな感じの運用でいいのではないかと思います。

結果

これでやった結果、16ノードを動かして、180秒で返ってくるようになりました。単純に割った数だけで済まないのは、各テストのイニシャライズに関してはやっぱり等しく時間がかかってくるからです。そういったところに関しては、やっぱり単純に割った数くらいほどには速くはならないなという結果でした。

とは言え、2,000秒が180秒くらいで返ってくるようになったので、結構ライフチェンジングだったなあという感じです。

これは簡単で、コンフィグに素直にサーバーを足せばスケールします。要はサーバーをセットアップして単独でmake testが通れば、クラスターに投入してオッケーですね。これはPuppetでどうにかなります。

それに、再実行ボタンが気軽に押せるようになりました。というのは、180秒で結果が返ってくるので、何らかの失敗があってもすぐ押せば、もう1回チェックをして結果が見られるからです。

手元で2,000秒待つよりは、プッシュしたほうが速い。ですので、ほかの人の開発アクティビティが見えやすくなるという副次的な効果がありました。これは嬉しい誤算ですね。

手元でやるよりプッシュしたほうが速いということになると、とりあえずみんなブランチを作ってプッシュしよう、という感じになる。つまり、そういう文化になるように仕向けることができるんです。

チームメンバーのコードを早めに見てツッコんだりツッコミをもらったり、というようなツッコミビリティが上がって、結果、開発品質や速度はもちろん、フルテストが早く終わるので、品質も向上を図れるかなという手応えがありました。高速なテストは開発文化を変えるんだなあと感じています。

改善構想

とは言え、まだまだ改善する余地はありまして、テストが通せなかったサーバーはそもそもスキップしてどこかでリトライして自動でやろうよという案を考えています。それ以外にも、proveのjオプションを使えるようにテストを直して、ちゃんと(CPU)コアは使い切るというアイデアもあります。それがどうしてもできなかったら、LXCとかVMでもいいんですけど、1ノードあたりの実行環境をできるだけ増やしてあげれば、もっと速くなるかなとは思っています。

わりと一般的なCPANモジュールの組み合わせだけで、フルテストを分散実行して高速化する枠組みを実装して、運用しています。

個別の対応はやるべきだと思うし、みなさん、soh335さんのスライドを読んだほうがいいと思うんですけど、それだけでは足りなくなって来るときは、テストを書きまくってたらいつか必ず来ます。そういうときには、このスケールするやり方だと、わりと簡単に移行できるのでお勧めです。

終わりに



FreakOutはPerlアプリケーションで書いてるんですけど、そのテスト方法とかCIとか、フルテスト実行のスケールアウト手法についてご紹介しました。結構地味な手法だと思うんですけど、テストを高速に回し続ける環境がこれでできたので、これでリリース速度と品質の両面をカバーすることができているんだなあと考えています。 それと、今回の内容は、来月発売のWeb+DB PRESS、Perl Hackers Hubに一部掲載されます。最初のおさらいは飛ばしたんですけど、それ以外のテストクラスターに関しても、サンプルコードがgihyo.jpで公開されますので、ぜひお買い求めください。

それと、終わりにもうひとつ。テストはどんどん書こうということは訴えたいなと思います。「テストを頻繁にせよ。コンパイル時にはテストを局所化して、1日に最低1度はすべてのテストを実行せよ」とマーチン・ファウラーが言っているとnaoyaさんが書いていますけど、もうプッシュごとにテストしようよと。どんどん書いて、ということですね。高速なテストっていうのは開発文化を変えます。だから、みなさんどんどんテストを書きましょう。 

FreakOutでは課題の認識／解決に技術で向き合い、アウトプットしていくエンジニアを募集していますので、ご関心のある方はこちらをご覧ください。または、手近なFreakOut社員を見つけて話を聞くなど、ありだと思います。ぜひぜひよろしくお願いいたします。これで私のトークは終わりにさせていただきます。ありがとうございました（拍手）。

司会：何か質問がある方はいらっしゃいますか。あと12分ぐらいあるのでぜひ。

質問者：直接伺ってもいいですか？Jenkinsだと、分散実行がnativeでサポートされていると思うんですけれども、そっちではなくてUkigumoの改良のほうに選んだという理由があれば、聞かせていただきたいです。

久森：Perlで完結するからですね。あと、Jenkinsというよりは、最初にUkigumoでのサイクルを作っていたので、Jenkinsの分散実行について調べる前に、これでできてしまうので書いたというのもあります。

質問者：そっちのほうがコストが安い？

久森：うーん、そんなに時間がかからずに実装できたので、まあ、いいかなと。あと、Jenkinsの作法を知っている人があんまり社内にいなかったというのもあります。ですので、社内にJenkinsおじさんがいたらそっちでやってもいいのかなとは思います。

質問者：ほかの方もタイムライン上で話してたんですけど、テストケースが増えていくとどうしても重複しているテストが増えていきますよね。そういうものを減らすことによってテスト時間を減らしたいけれど、そういう方法論がまだあんまりないのかなという感じがしてるんですけど、その辺りに関しては何か考えていることはありますか？

久森：コードを書いてる人が気づいたベースで削っていくっていう感じなのかなと思います。今タイムラインを読み始めたところなので。

質問者：でもそういう話です。

久森：重複したテストは、気づいたら削るぐらいかなというのが、今のところの考えですね。

質問者：まあそうですよね。ありがとうございます。

久森：逆に、いいソリューションがあれば、ぜひ登壇して発表していただきたいです。その他にいらっしゃれば。

それでは、今日はどうもありがとうございました。2日間お疲れ様でした（拍手）。




2日間お疲れ様でした。前夜祭から言うと3日ですか。ずっと人の話を聞くというのは結構疲れると思うので、簡単に進めたいなと思います。

僕のトークタイトルなんですけど、「フルテストも50msで終わらせたい」というタイトルで、Perlのmake testっていうのが遅くなってきたのでそれをどう解決したか、そういう話をしたいと思います。

僕、自己紹介なんですけど、久森達郎（ヒサモリ・タツロウ）って言います。だいたいmyfinderっていうIDでtwitterなどしています。FreakOutという会社に勤めてまして、今はインフラのチームにいてサーバーの面倒をみたりとか、あとはグラフとにらめっこしたり、そういった仕事がメインです。

![](http://30d.jp/img/yapcasia/6/700_large.jpg "(c) Japan Perl Association")

去年は嬉しいことにフリークアウトのシステムをご紹介して、Best Talk Awards 3を頂きまして、非常にこうありがたく思っております。

## 50ms or die

こういう感じですね。

で、最初になんですけど、すいません、さすがに50msではメインテストは終わりません。それは無理です。はい。

で、今日話すとこなんですけど、Perlアプリケーションの基本的なところ。それからFreakOutのテスト環境とCIというのはどうやってきたかとか。どういう推移でここ1、2年やってきたかみたいなお話をして、それから増えたテストっていうのをどうやって高速化していくみたいな話になります。

## 今回話さないこと

今日は、画面系のテストに関しては話しません。昨日午前中に同僚のモリヤマさんがBrowserStackを使ったテストについて話をしてくれました。この資料はもう確か上がっているはずなので適当に探してください。

Real Time Biddingそのもの、FreakOutのシステム自体の話では、もう昨年のトークの資料で、WEB+DB PRESSに書いた記事ってのがあるので、そちらを参照してください。ボリューム70なんで今本屋にはないですけど、総集編が今本屋にあります。

## Web-DB press総集編Vol.1〜72の表紙

こういう表紙です。はい。なので皆さんお買い求めください。

あと、テストモジュールに関して踏み込んだ使い方みたいなところっていうのは、昨日すごい、soh335さんの話とだだかぶりしていたので、スキップして行こうかなと思います。なので最初に話したPerlのテストおさらいをさらっと流す感じで話していきます。

## Perlのテストのおさらい

で、最初にPerlのテストなんですけど、わりとちゃんとPerlのテストを書いてるぜっていう、おれのプロダクトたちは書いているぜみたいな。（客に手を挙げさせる）素晴らしい。まあみんな書いてる。いるっていっても10％ですね。

ということで、いろいろと基本的なモジュールに関して話していこうと思ってたんですけど、この辺は（スライドを流していく）、Test::More、Test::MockTime、Plack::Test、Test::mysqld、だいたいこれくらい使えば基本的なテスト用途は満たせていい感じですっていう話で。ここはまるかぶりしていたので、soh335さんのスライドの資料にお任せをします。

で、FreakOutのテスト環境とCIの話なんですけど、基本的にアプリケーションはPlack::Testでだいたいカタがつくケースが多くて、画面系以外のところに関してはほとんどHTTPの通信とかで、画面とか伴わないので、基本的にリクエスト/レスポンスに落としやすい、というところで。

ちょっと潰れちゃってますね。Plack::TestのSYNOPSISに書いてあるようなものをそのまま書いただけです。これでリクエストとアプリケーションを作って、そのテストの中でそれを使ってリクエストを実行してテストする、そんな感じです。

## CLI（バッチ）処理

CLIとかどうしてるかっていうと、単独のモジュールで開発した後、CLIラッパーみたいなモジュール、フレームワークが社内にあるので、それを使ってラップして呼びだしているということなんで、基本的にはCLIっていうのを意識してモジュール書くというよりは、処理を書いてそれをCLIでラップしてというような作りしています。

## ログ処理

ログ処理なんですけど、基本的にはダミーのログを特定のディレクトリに置いて、そこでそれを対象に集計処理とかをかけて、処理後はクリーンアップするみたいな。まあ一般的に皆さんよくやるような処理をやっています。

で、これはsoh335さんも話してたんですけど、うちもt::Utilsというのに入っていて、ここでテストを捗らせるために、接続先DBをテスト用に置き換えたり、テストごとにミドルウェア起動して空いているポートを探したりというのは全部、こういうt::Utilsの下にこういうモジュールを作って、それをuseすることで処理して、毎回テストでは書かないようにする、みたいなことをやっています。

なので、Perl以外のミドルウェア、mysql、memcached、あとTT(Tokyo Tyrant)を使っていますけど、それ以外にRiakとか入れ始めたので、Riakの起動停止もこのへんでフォローするというようなことをやってます。

## リスト

こんな感じですね。config fileを最初に上書きして、そのあと下の、別途メソッドにしているんですけど、test memdとか、test●とか、test dbとか、そういう感じですね。これでinitializeしている、そんな流れです。

## ヘルパモジュール

もう1個、ヘルパモジュールというのを書いていて、別途、手元でmake testを走らせたいときとかに、Test::Prettyに差し替えたいような要求を吸収するために作られてます。で、runtests、あとは、runtestsのテスト一覧を渡す前にシャッフルするみたいなことをやってます。

## Makefile.PL

Makefile.PLと書かれています。あー潰れちゃってます。見えます？ スライドあげるので見て下さい。Makefileの中にMT::test\_via\_harnessという、自分のモジュールに置き換えてそれを処理してもらうという感じの書き方をしていて、その実際のMakeHelperの中でこんな感じで、Harness classに置き換えて、引数にprettyが当たっていればTest::Prettyを使って、ということでもって、そんなことができます。

テストをシャッフルするっていうのもやってて、これは単純にFile::Findで持ってきて、最後シャッフルをかけてruntestsに渡すみたいなことをやっていて。

これは結構、もしやってない人がいたらやったほうがいいなと思っている策で、結構知らない間に順序に依存するテストを書いてしまうことってあると思うんですよ。あと、自分が書いたテストの結果に依存したテストをほかの人が書いちゃうのがあって。最後のはいいです。

具体的にはDBのクリーンアップ漏れが発生して、本当は消えてないといけないレコードが入っていることを期待するテストを書いちゃうとか。あとは、ほかの人がクリーンアップするように直したほかのテストをfailしちゃうみたいなケースとかは、たいへん気づけない。

あと、同じファイルを違うテストから参照するケースとかも、このへん、本当はFile::Tempとかを使ってそのテストで閉じたものをやるべきなんですけど、そうなってない場合とかというのは、コンフリクトする可能性があります。そんな感じなので、これはわりとサクッとできるので、もしやられてない方がいたらやったほうがいいかなと思ってます。

## Ukigumoとのつきあい

次、Ukigumoとのつきあいですけれども。特にUkigumoサーバー、手は入れてません。そのまま立ち上げているだけです。Ukigumoクライアントは使ってなくて、独自にクライアントを実装してます。

FOutTesterという名前で社内で作っていて、CIを開始するための枠組みで、テストに未実効のブランチがあるかないかをバッチで毎分kickしてして探してきて、実行します。で、SQLiteに実行したブランチ名とリビジョンを記録しておいて、2回同じテスト走らないようにしている、という感じ。

で、テスト結果をUkigumoサーバー以外にポストするという処理をそこに書いていて、今はせいぜいメールぐらいですけれども、IRCを使っている場合はそこでIRCにpostしてもいいのかなと思います。

## 画面を変えている

こんな感じでテスターのbase classを作っていて、その中で、実体はこのrunの中か、このgithubのリポジトリを取ってきて、指定のプロジェクトをrunして、結果までparseされてUkigumoに投げるみたいな。Ukigumoに投げる処理は普通に、LWPに任せるみたいな話の処理ですね。というのがわかる。

これを継承したそれぞれのプロジェクトいうのもあったりします。ファイルが..これだと読めないか。

## ここまでのまとめ

という感じで、基本的なテストで、FreakOutのテストとUkigumoちゃんとの付き合いというのを話して、ここまで説明をしました。

実施済みのブランチを記録して2回実行させないとか、テストを実行するにあたってヘルパモジュールをこさえて捗らせるということをやってます。

という感じで、いったんここまでで小休止したいんですけど。ご質問等あれば。手を挙げていただいて。その隙に水飲ましてください。特にございません？ 大丈夫そうでね。

じゃあ次。ようやく本題の増えたテストの実行の高速化っていう話になるんですけど。その前に、FreakOutのテスト、ここまで形を作りましたけど、ここに行くまで結構いろいろ1年の間にありまして。1、2年の間、こんな感じで遷移しました。

去年のYAPC前までは3〜4人で開発してまして、あんまりちゃんとCIとか整備してなくて、手元のVMで実行して良ければチェックしてマージしてリリースということをやってたんですね。

すぐに結構多人数になってきまして、ここでCI入れようねっていうことで。メンバーみんなでCI環境を急速に整備していって、ここまでで話したような技法とかいうものを作りました。

で、今年に入ってからさらに倍ぐらいの人数に増えていて、ブランチとか数増えてきてプッシュされるとテスト走るようになっているんで、同時に実行したいテストはCI実行順番待ちが出るようになって、単体でも時間がかかるので順番待ちしているととても時間がかかるというような状況になっちゃってました。

で、現状なんですけど、.t file（ドット･ティー･ファイル）だけでも800以上、直近で渋谷(会場に居る同僚)さん、何件ありましたっけ？僕が見たメールで830いくつとか、そのぐらいです。いうようなテストファイルがあって、これ、make testを愚直に打つと2000秒ぐらい返って来ない。3、40分返って来ないかな。っていう感じで。結構つらいねという感じでした。

そもそも時間掛かりすぎですよと。ブランチがいくつもあると結果がわかるまでにすごい待たされちゃう。例えば5個開発ブランチがあって、活発にプッシュされていると30分かけて結構な。すごいですね。3時間ぐらい待たされるのか。プッシュしたらもうその日は結果が分かるまでリリースできないけど、結果が分かるの8時過ぎちゃうからDeployできないからまた明日になるとか、そういうすごい開発速度が遅くなっちゃうみたいな事態が起こったりするという状況になって来ました

で、そんな感じでですね。待たされた末にfailしていると切なくてちょっとやる気がなくなっちゃいますね。そうなってくると、事故るリスクが高まってくるっていうのはどうしてかというと、テスト遅いし、CI通すと遅いからもう手元でとりあえずテスト通して、オッケーならマージして出しちゃえみたいなことをやるっていう人が出てきたりする。そして誰もフルテストをしなくなっていくみたいな話になると、せっかくここまでサイクルを作ったのに全然使われなくなっちゃう。形骸化してっちゃう。そうなると意味がないですよね。

これ同僚の人のツィートなんですけど、なんか関係ないと思っててもテストが落ちたというケースが出てくる。これはフルテストを通さないと気づかないっていうことも多々あるので、やっぱり常にフルテストを早く通し続けるっていう環境を作んないといけないよね、というような話で、まあテストをするのをやめるのは論外だし、テストが終わるまで愚直に待つのは全然解決になってないと。

で、proveには-j（ハイフンジェイ）ってオプションがあるんですけど、ちょっと深遠な理由でこれを使えないと。ちょっと使うとfailするっていうもがあるので、これを使うとちょっと大幅に改修しなきゃいけないねという事案が1件あったのと、それ以外の高速化で事前起動できるものは競合を起こさないものの対応を進めたりというのはちょいちょいやってはいます。ただ、さっきもお話した通りテストの数が多いので、やっぱり単独での高速化っていうのはどっかで限界を迎えるでしょうというような話になりました。

なので、スケールするやり方に変わらないといけないと。ということで、高速化にあたってこんな感じで要件を決めました。

まず、すでに書いてあるテストっていうのは触らなくていい。書かれたテストっていうのはそのまま。既存のCIサーバーはそのまま使いたいと。Ukigumoは、Ukigumo::Serverはは引き続き使いたいと。なので、これはちょっとそのままにしようという話をしました。

であと、やっぱりちゃんと、先ほど話したんですけど、スケールすること。例えばテスト数が10倍になったとか、平行する開発数が10倍になったとか、そんな状況になっても吸収できる枠組みであること。というのが要件でした。

そこで、分散実行をさせましょうというアイデアを立ててですね、複数のサーバーに分散でリクエストを投げて、その実行結果を返して集計する、というのができればノードを追加してスケールするみたいな枠組みに落とせそうだなという話でした。

で、サーバーの追加とかメンテが簡単にできるように、簡単なコンフィグファイルだけでサーバーノードを管理すればいいよね、みたいな感じに理想をしようとしてました。

あと、複数のサーバーにリクエストを投げるので、ネットワークの理由とか何らかの理由でテストファイル、1台のサーバーがフェイルしたみたいなことがあるので、再実行というものをまずできるようにしようと。というのはSQLiteを実行済みのブランチなんかは保存するようにしちゃって、その辺は簡単にコントロールできるようにしましょうと。というので実装してます、しました。

## 分散実行の仕組み

で、簡単にいうとこういうことですね、という話です。サーバーノードの中でブランチ、そのプッシュされたブランチの中に入っている実行対象テストのリストを取ってきて、クラスターの台数分で等分割します。その等分割したテストの一覧を各サーバーに投げて実行した結果を返してもらって集計して、Ukigumoとそれ以外というようなレポート名になってますけど、そういったファイルをポストするっていうような仕組みです。

で、それぞれ簡単な、よく知られたCPANモジュールだけで、この辺は書けるので、実際にやってることはすごく簡単です。例えばテストのピックアップとシャッフルというのはFile::FindとList::MoreUtilsで普通に分割して、クラスター名をキーにした配列とかにぶっ込んでおけば割り当てができますねと。で、クラスターノードでの実行命令とか結果受取、これはシリアルにやっちゃうとまずいので、Parallel::ForkManagerを使えばできますので。で、結果のパースとかはPerlの得意なところなので言わずもがなと。で、Ukigumoへのポストは先ほどのコードの通り、LWPで書いてポストで、それで終わらしてしまえと、いうような感じです。

で、これがサーバー側なんですけど、今度実行するクラスター側って何やってるかというともっと簡単で、TAP::Harness::runtestsにテスト一覧を渡して実行するだけです。

## コードサンプルで解説

ということで、ちょっとコードサンプルで解説します。

あーこれ見えないな。見えないですけど、単にハッシュに突っ込んでるPerlのファイルです。これは飛ばします。

これは。

実行することは単純で、Parallel::ForkManagerでコンフィグに書かれている台数分プロセスを上げて、それぞれforで回して、Net::OpenSSHでテストリストを投げて、先にgit fetchさせて最終的に実行した結果を受け取ると。

で、最近のParallel::ForkManagerだと、run\_on\_finish、どこだ。というmethodで、ここだ。ここの、フィニッシュしたときに任意のcode refみたいなものを渡して、処理に渡してデータを集計できるので、子プロセスでsshを投げて、クラスターノードの実行した結果を受け取ったら、親プロセスに渡すときにこういうやり方をすると簡単に取れるので、バージョンいくつだったか忘れましたけど、新しいParallel::ForkManagerを入れると、とっても捗ります。

パースするところは単純に、全部のテストがどのくらい走ったかと、どのくらいフェイルしたかしか計測はしてなくて、単純に集計するだけになっています。

これがクラスターノードで実行しているランチャーなんですけど、ホント簡単ですねと。オプションで、今はわかんないですけど、デリミタでリストを渡してますけど、そいつをスクリプトしてruntestsに渡すだけですから。こっち側ではシャッフルはする必要なくて、というのはマスターの側でもうシャッフルはしてあるので、ここは受け取って実行するだけでいいというようなものです。

## 再実行

で、これが実行するところなんですけど、次、再実行の話で。再実行するときはマスターノードで再実行用のWeb appを起動しておいて、リクエストをかけたらその実施状況を保存しているSQLiteからそのブランチを削除するだけみたいな、簡単なアプリケーションを起動して待つ。

あと、これはkanさん書いてくれたのかな、ですけど、Chrome拡張でUkigumoのサーバーにボタンを追加するみたいな対応で、再実行が簡単にできるようにしています。画面はこんな感じで、この、「リトライ」っていうボタンですね。これを追加するような、そんな感じの対応をしています。なので、このフェイルしてるっていう内容が、単純にテストだけでこけてる場合だったら直すべきなんですけど、特定のサーバーだけ応答がないとかっていう結果が出てる場合は再実行ができるようになってます。

## 動かすサーバー

で、動かしているサーバーなんですけど、社内にこんな感じで余った自作サーバーのパーツを寄せ集めて作ってます。なので、ご家庭に余っているあり合わせのパーツがあればそれでも作れます。というのはうちの事情なんですけど、まあAWSでいいんじゃないですかね、と思います。必要な時間だけサーバーの動作をスタートして、要らなくなったら、就業時間が終わったらストップする、そんな感じの運用でいいのかなと思います。

## 結果

これでやった結果どうなったかなんですけど、16ノード動かして180秒で返ってくるようになりました。単純に割った数だけで済まないのは、各テストのイニシャライズに関してはやっぱり等しくかかってくるので、そういったところに関してはやっぱり単純には、割った数くらいには速くはならないなという結果でした。

とは言え、2,000秒が180秒くらいで返ってくるようになったので、結構ライフチェンジングだったなあという感じです。

で、これは簡単でコンフィグに素直にサーバーを足せばスケールすると。要はサーバーをセットアップして単独でmake testが通ればクラスターに投入してオッケーですね。これはPuppetでどうにかなります。

で、再実行ボタンが気軽に押せる。というのは、180秒で結果返ってくるので何らか失敗あってもすぐポチっと押せば、もう1回チェックをして結果が見れると。

手元で2,000秒待つよりはプッシュしたほうが速い。なので、ほかの人の開発アクティビティが見えやすくなるっていう副次的な効果がありました。これが嬉しい誤算ですね。

手元でやるよりプッシュしたほうが速いっていうことになると、とりあえずみんなブランチ作ってプッシュしようぜ、みたいな感じになる。そういう文化になるように仕向けることができるということなんです。

なので、チームメンバーのコードを早めに見てツッコンだりツッコミもらったり、というようなツッコミビリティが上がって、結果、開発品質、速度はもちろん、フルテスト早く終わるんで上がるんですけど、品質もまあ向上を図れるかなと、そんな感じでした。なので、高速なテストというのは開発文化を変えるんだなあとみたいなことを感じました。

## 改善構想

とは言え、まだまだ改善する余地はありまして、テストが通せなかったサーバーはそもそもスキップしてどこかでリトライ自動でやろうよという話はまあ考えてて。それ以外にproveのjオプション使えるようにテストを直して、ちゃんと(CPU)コアは使い切りましょうという話とか。それがどうしてもできなかったら、LXCとかVMでもいいんですけど、1ノードあたりの実行環境をできるだけ増やしてあげるということをすれば、もっと速くなるかなというふうには思ってます。

なので、わりと一般的なCPANモジュールの組み合わせでフルテストを分散実行して高速化する枠組みというのを実装できて、今運用してます。

で、個別的なやり方というのは全然すごくやるべきだと思うし、みんなsoh335さんのスライド読んだほうがいいと思うんですけど、それだけでは足りなくなって来るっていうのは、テスト書きまくってたらいつか来るので、そういうときにはこのスケールするようなやり方に、わりと簡単に移行できるのでおススメです。

## おわりに

![](http://30d.jp/img/yapcasia/6/703_large.jpg "(c) Japan Perl Association")

で、おわりになんですけど、FreakOutはPerlアプリケーションで書いてるんですけど、そのテスト方法とかCIとか、フルテスト実行のスケールアウト手法について紹介しました。で、結構地味な手法だと思うんですけど、テストを高速に回し続ける環境がこれでできたので、リリース速度と品質の両面をカバーすることっていうのは、これでひとつできているんだなあと考えています。
で、今回の内容は来月発売のWeb+DB PRESS、Perl Hackers Hubに一部掲載されます。最初のおさらいはすっ飛ばしたんですけど、それ以外のテストクラスターのほうに関しても、サンプルコード、gihyo.jpで公開されます。なので、ぜひお買い求めください。
おわりにもうひとつ。テストはどんどん書こうということは訴えたいなと。こんなことをnaoyaさんがお話ししてましたけど、「テストを頻繁にせよ。コンパイル時にはテストを局所化して1日に最低1度はすべてのテストを実行せよ」とマーチン・ファウラーが言っていると書いてありますけど、もうプッシュごとにテストしようよと。どんどん書いて、ということですね。高速なテストっていうのは開発文化を変える。なので皆さんどんどんテストを書きましょう。
ということで、FreakOutでは課題の認識／解決に技術で向き合い、アウトプットしていくエンジニアを募集しているので、ご関心のある方はこちらをご覧ください。ないし、FreakOut Tシャツは、昨日みんな着てたから今日着てないのかな。まあなので、手近なFreakOut社員を見つけてお話しを聞くなど、ありだと思います。なので、ぜひぜひよろしくお願いいたします。ということで私のトークは終わりにさせていただきます。ありがとうございました（拍手）。

司会：何か質問ある方、いらっしゃいますか。あと12分ぐらいあるのでぜひ。

質問者：直接いいですか。Jenkinsだと、分散実行がnativeでサポートされていると思うんですけれども、そっちじゃなくてUkigumoの改良のほうに選んだという理由があれば、聞かせていただきたい。

久森：まあPerlで完結するからですかね。あとJenkinsというよりは、最初にUkigumoでのサイクル作ってたんで、Jenkinsのその分散実行について調べる前に、これでできちゃわねっていうんで書いたというのもあります。

質問者：そっちのほうがコストが安い？

久森：うーん、そんなに時間かからずに実装できたので、まあ、いいかなと。あと、Jenkinsの作法を知っているみたいな人があんまり社内にいなかったというのもあります。なので、社内にJenkinsおじさんがいたらそっちでやってもいいのかなというふうには思います。

質問者：ほかの方もTL上で話してたんですけど、テストケースが増えていくとどうしても重複しているテストとか、そういうのが増えてって、そういうものを減らすことによってテスト時間を減らしたいみたいなところで、結構そういうなんか方法論が、まだあんまりないのかなという感じがしてるんですけど、その辺りに関して何か考えてることとかありますか。

久森：コード書いてる人が気づいたベースで削っていくっていう感じなのかなっていう。ちょっと今タイムライン読み始めたので。

質問者：でもそういう話です。

久森：重複したテストは、気づいたら削るぐらいかなというのが、今のところ。

質問者：まあそうですよね。ありがとうございます。

久森：逆に良いソリューションがあれば、ぜひ登壇して発表していただきたいです。その他、いらっしゃれば。


今日はどうもありがとうございました。2日間お疲れ様でした。（拍手）


